💬 Context-aware conversational AI
Understands and responds using prior conversation context.

🔍 RAG-based retrieval from local knowledge base
Fetches relevant context from a Qdrant vector store.

🌐 Web search fallback for missing or limited information
Uses Tavily with Brave search to supplement answers in real time when local data is insufficient.

🧠 Easily extendable and fine-tunable
Built on modular components allowing easy customization and scaling.

📦 Designed for modularity and ease of integration
Uses LangGraph for defining custom agent workflows and stateful interactions.

⚡ Powered by LLaMA 4 on Groq
Ultra-fast and cost-efficient inference leveraging Groq’s low-latency LLM runtime.

